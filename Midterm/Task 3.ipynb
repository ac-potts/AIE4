{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain-core==0.2.40 langchain-openai==0.1.25 langchain-huggingface==0.0.3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU pymupdf ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangChain API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIM - SDG - {uuid4().hex[0:8]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Source Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\andre\\\\OneDrive\\\\Documents\\\\AIE4\\\\AIE4\\\\Midterm'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "bill_docs = PyMuPDFLoader('Blueprint-for-an-AI-Bill-of-Rights.pdf').load()\n",
    "nist_docs = PyMuPDFLoader('NIST_report.pdf').load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = bill_docs + nist_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "generator_llm = ChatOpenAI(model=\"gpt-4o-mini-2024-07-18\") #changed from gpt-3.5-turbo\n",
    "critic_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm,\n",
    "    critic_llm,\n",
    "    embeddings\n",
    ")\n",
    "\n",
    "distributions = {\n",
    "    simple: 0.5,\n",
    "    multi_context: 0.4,\n",
    "    reasoning: 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28aa592bb41e45e3929b097c843cdc0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes:   0%|          | 0/284 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filename and doc_id are the same for all nodes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7798392e107e461d8a153bede13bc831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['GAI system incidents', 'Organizational risk management', 'Incident response processes', 'Third-party GAI resources', 'Data privacy and localization compliance']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Human subject protection', 'Content provenance', 'Data privacy', 'AI system performance', 'Privacy-enhancing technologies']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Prompt injection', 'Indirect prompt injection attacks', 'Data poisoning', 'Intellectual property risks', 'Obscene and degrading content']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Data privacy', 'Identity theft', 'Facial recognition system', 'Surveillance software', 'Employee discussions about union activity']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['GAI technologies', 'Content provenance', 'Synthetic content detection', 'Digital transparency mechanisms', 'Provenance data tracking']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Healthcare navigators', 'Biden-Harris Administration', 'Automated customer service', 'Human-AI systems', 'Ballot curing laws']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['GAI lifecycle', 'AI technology risks', 'Organizational practices for AI', 'Impact documentation process', 'Content provenance methodologies']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['GAI system incidents', 'Organizational risk management', 'Incident response processes', 'Third-party GAI resources', 'Data privacy and localization compliance']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Synthetic training data', 'Model collapse', 'Environmental impact', 'GAI systems', 'Carbon capture programs']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Synthetic training data', 'Model collapse', 'Environmental impact', 'GAI systems', 'Carbon capture programs']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 3, 'depth': 3, 'structure': 3, 'relevance': 3, 'score': 3.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AI Bill of Rights', 'Automated systems', 'Civil rights and liberties', 'Access to critical resources', 'Framework for protections']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.25}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AI Bill of Rights', 'Stakeholder meetings', 'Private sector and civil society', 'Positive use cases', 'Potential harms and oversight']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['GAI technologies', 'Content provenance', 'Synthetic content detection', 'Digital transparency mechanisms', 'Provenance data tracking']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.25}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AI Bill of Rights', 'Stakeholder meetings', 'Private sector and civil society', 'Positive use cases', 'Potential harms and oversight']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 1, 'structure': 2, 'relevance': 2, 'score': 1.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AI Bill of Rights', 'Algorithmic discrimination protections', 'Data privacy', 'Human alternatives', 'Automated systems']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 1, 'relevance': 3, 'score': 1.75}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AI Risk Management Framework', 'Trustworthy AI', 'Bias in Artificial Intelligence', 'GPT-4 Technical Report', 'Unsafe Diffusion']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What criteria are used to measure AI system performance or assurance in deployment settings?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What procedures should be established for escalating GAI system incidents to the organizational risk management authority?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What are the intellectual property risks associated with GAI systems?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What are some examples of how data privacy principles aim to protect against identity theft?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What applications can GAI technologies be leveraged for?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What was the purpose of the meetings conducted by OSTP regarding the AI Bill of Rights?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What organizational practices are necessary for enabling AI testing and incident identification?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What considerations should be taken into account when assessing the environmental impact of GAI systems?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the significance of content provenance in managing risks associated with AI-generated synthetic content?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the purpose of ballot curing laws in the voting process?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What are the considerations for data privacy and localization compliance in the context of GAI system risks?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What resources are available for understanding the AI Risk Management Framework?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What considerations should be taken into account when assessing the environmental impact of GAI systems?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What are the key considerations regarding data privacy in the context of the AI Bill of Rights?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What types of critical resources should be accessible to individuals and communities according to the Blueprint for an AI Bill of Rights?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What role did the private sector and civil society play in the development of the Blueprint for an AI Bill of Rights?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the criteria used to measure AI system performance or assurance in deployment settings. It is clear and specific, indicating the focus on AI systems and their performance metrics in a particular context (deployment settings). The intent is unambiguous, allowing for a direct response based on general knowledge of AI performance metrics. Therefore, it meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the intellectual property risks associated with Generative AI (GAI) systems. It is specific and clear in its intent, focusing on a particular aspect of GAI systems—intellectual property risks. The question can be understood and answered without needing additional context or external references, making it self-contained. Therefore, it meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question is specific and seeks information about the procedures for escalating incidents related to GAI systems to the organizational risk management authority. It is clear in its intent and does not rely on external references or context, making it understandable and answerable. However, to enhance clarity, it could specify what types of incidents are being referred to (e.g., security breaches, operational failures) or the context in which these procedures are to be applied (e.g., specific industries or organizational sizes). This would provide a more focused framework for the response.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"What procedures should be established for escalating GAI system incidents to the organizational risk management authority?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the applications of GAI (General Artificial Intelligence) technologies, which is a clear and specific inquiry. However, the term 'GAI technologies' may not be universally understood, and the question could benefit from a brief definition or context regarding what GAI encompasses. Additionally, specifying the types of applications (e.g., in healthcare, finance, education) could enhance clarity and focus. Overall, while the question is understandable, it could be improved by providing more context or examples to guide the response.\", 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks for the purpose of meetings conducted by the OSTP (Office of Science and Technology Policy) regarding the AI Bill of Rights. It is specific and clear in its intent, as it directly seeks information about the purpose of these meetings. However, it assumes familiarity with the OSTP and the AI Bill of Rights without providing any context or background information. To improve clarity and answerability for a broader audience, the question could include a brief description of the AI Bill of Rights or the significance of the OSTP's involvement in this matter.\", 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the purpose of ballot curing laws in the voting process, which is specific and clear in its intent. It does not rely on external references or additional context, making it independent and self-contained. The question is understandable and answerable based on the details provided, as it seeks information about a specific legal aspect of voting. Therefore, it meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"What is the purpose of ballot curing laws in the voting process?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks for examples of how data privacy principles protect against identity theft. It is clear in its intent and specifies the topic of interest (data privacy principles and identity theft), making it understandable and answerable without needing additional context. However, it could be improved by specifying which data privacy principles are being referred to (e.g., GDPR, CCPA) or by asking for examples from a particular context (e.g., legal frameworks, organizational policies). This would help narrow down the response and provide more targeted examples.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the significance of content provenance in the context of managing risks related to AI-generated synthetic content. It is specific in its focus on content provenance and its relevance to risk management, making the intent clear. However, the question may require some background knowledge about both content provenance and AI-generated synthetic content to fully understand the implications of the inquiry. To enhance clarity and answerability for a broader audience, it could be beneficial to briefly define 'content provenance' and outline the types of risks associated with AI-generated synthetic content that are being referred to.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"What is the significance of content provenance in managing risks associated with AI-generated synthetic content?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the organizational practices necessary for enabling AI testing and incident identification. It is specific and clear in its intent, focusing on the practices required for a particular purpose (AI testing and incident identification). The question is independent and does not rely on external references or context, making it understandable and answerable based on the details provided. Therefore, it meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the resources available for understanding the AI Risk Management Framework. It is clear in its intent, specifying the topic of interest (AI Risk Management Framework) and seeking information on resources. However, it could be improved by specifying the type of resources desired (e.g., articles, guidelines, courses) or the context in which the framework is being applied (e.g., industry-specific, regulatory). This would help narrow down the response and make it more targeted. Overall, the question is understandable and answerable based on the details provided.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] simple question generated: \"What resources are available for understanding the AI Risk Management Framework?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What criteria and protocols should be established for the escalation of GAI system incidents to the risk management authority, ensuring safe decommissioning and effective communication of risks?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the types of critical resources that should be accessible to individuals and communities as outlined in the Blueprint for an AI Bill of Rights. It is specific in its focus on the Blueprint and the resources it mentions, making the intent clear. However, the question assumes familiarity with the Blueprint for an AI Bill of Rights without providing any context or details about it. To improve clarity and answerability, the question could include a brief description of the Blueprint or specify the types of resources being referred to, which would help those unfamiliar with the document to understand and respond appropriately.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What types of critical resources should be accessible to individuals and communities according to the Blueprint for an AI Bill of Rights?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the considerations for assessing the environmental impact of GAI (General Artificial Intelligence) systems. It is clear in its intent, specifying the topic of interest (environmental impact of GAI systems) and seeking information on the factors to consider. The question is independent and does not rely on external references or context, making it understandable and answerable based on the details provided. Therefore, it meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"What considerations should be taken into account when assessing the environmental impact of GAI systems?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What mechanisms do ballot curing laws implement to ensure voter rights are upheld when automated signature matching systems may fail?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the considerations for assessing the environmental impact of GAI (General Artificial Intelligence) systems. It is clear in its intent, specifying the topic of interest (environmental impact of GAI systems) and seeking information on the factors to consider. The question is independent and does not rely on external references or context, making it understandable and answerable based on the details provided. Therefore, it meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"What considerations should be taken into account when assessing the environmental impact of GAI systems?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about key considerations regarding data privacy specifically in the context of the AI Bill of Rights. It is clear in its intent, specifying both the topic (data privacy) and the relevant framework (AI Bill of Rights). The question is self-contained and does not rely on external references, making it understandable and answerable based on the details provided. Therefore, it meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What role does tracking the origin and history of AI-generated content play in mitigating risks associated with its authenticity and user trust?\"\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'AI system performance or assurance criteria are measured qualitatively or quantitatively and demonstrated for conditions similar to deployment setting(s). Measures are documented.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'Intellectual property risks from GAI systems may arise where the use of copyrighted works is not a fair use under the fair use doctrine. If a GAI system’s training data included copyrighted material, GAI outputs displaying instances of training data memorization could infringe on copyright. The status of generated content that is similar to but does not strictly copy work protected by copyright is currently being debated in legal fora. Similar discussions are taking place regarding the use or emulation of personal identity, likeness, or voice without permission.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about considerations for data privacy and localization compliance specifically in the context of risks associated with Generative AI (GAI) systems. It is clear in its intent, specifying the areas of interest (data privacy, localization compliance) and the context (GAI system risks). However, the term 'considerations' could be interpreted in various ways, such as legal, ethical, or technical aspects, which may introduce some ambiguity. To improve clarity and answerability, the question could specify the type of considerations being sought (e.g., legal frameworks, best practices, ethical implications) or provide examples of what is meant by 'GAI system risks'.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] simple question generated: \"What are the considerations for data privacy and localization compliance in the context of GAI system risks?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What factors should be evaluated regarding the environmental sustainability and societal implications of GAI systems, particularly in relation to training data diversity and community feedback mechanisms?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What factors should be evaluated regarding the environmental sustainability and societal implications of GAI systems, particularly in relation to training data diversity and community feedback mechanisms?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the role of the private sector and civil society in the development of the Blueprint for an AI Bill of Rights. It is specific in its focus on the entities involved (private sector and civil society) and the subject matter (AI Bill of Rights). However, the question may require some background knowledge about the Blueprint itself, which is not provided in the question. To improve clarity and answerability, the question could briefly define what the Blueprint for an AI Bill of Rights is or specify the aspects of the roles being inquired about (e.g., contributions, influences, or specific actions taken).', 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What role did the private sector and civil society play in the development of the Blueprint for an AI Bill of Rights?\"\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'GAI technologies can be leveraged for many applications such as content generation and synthetic data.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The purpose of the meetings conducted by OSTP regarding the AI Bill of Rights was to provide ideas related to the development of the Blueprint for an AI Bill of Rights and to offer useful general context on the positive use cases, potential harms, and/or oversight possibilities for these technologies.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': \"Some examples of how data privacy principles aim to protect against identity theft include: a data broker harvesting large amounts of personal data and suffering a breach that exposes individuals to potential identity theft, and an insurer collecting data from a person's social media presence to determine life insurance rates, which could lead to misuse of personal information.\", 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 3, 'depth': 3, 'structure': 3, 'relevance': 3, 'score': 3.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AI Bill of Rights', 'Automated systems', 'Civil rights and liberties', 'Access to critical resources', 'Framework for protections']\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'Organizational practices necessary for enabling AI testing and incident identification include establishing policies for measuring the effectiveness of employed content provenance methodologies and identifying the minimum set of criteria necessary for GAI system incident reporting, such as System ID, Title, Reporter, System/Source, Data Reported, Date of Incident, Description, Impact(s), and Stakeholder(s) Impacted.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The answer to given question is not present in context', 'verdict': -1}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 3, 'depth': 3, 'structure': 3, 'relevance': 3, 'score': 3.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Automated systems', 'Public consultation', 'Testing and deployment', 'Risk identification and mitigation', 'Safety and effectiveness']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['GAI systems', 'AI Actors', 'Unanticipated impacts', 'Information integrity', 'Content provenance']\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question is specific and seeks to understand the mechanisms of ballot curing laws in relation to automated signature matching systems and their impact on voter rights. It is clear in its intent, focusing on a particular aspect of election law and technology. However, it may benefit from a brief definition or context regarding 'ballot curing laws' and 'automated signature matching systems' for those who may not be familiar with these terms. This would enhance clarity and ensure that a wider audience can fully grasp the question's implications.\", 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question is specific and seeks information about the criteria and protocols for escalating incidents related to GAI systems to a risk management authority. It clearly conveys its intent, focusing on safe decommissioning and effective communication of risks. However, the question could benefit from a bit more clarity regarding what is meant by 'GAI system incidents' and the context in which these protocols are to be established. Providing a brief definition or context for 'GAI' and the types of incidents being referred to would enhance understanding and answerability. Overall, it is mostly clear and independent, but slight improvements could be made for broader accessibility.\", 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the types of resources that can aid in understanding AI risk management concepts. It is clear in its intent, specifying the subject matter (AI risk management) and the type of information sought (resources). However, it could be improved by providing more context or specifying the types of resources of interest (e.g., books, articles, courses, frameworks) to make it more focused. Additionally, mentioning the target audience (e.g., beginners, professionals) could help tailor the response further.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['GAI system incidents', 'Organizational risk management', 'Incident response processes', 'Third-party GAI resources', 'Data privacy and localization compliance', 'Decommissioning AI systems', 'GAI risks', 'Roles and responsibilities', 'Incident response procedures', 'Data security and retention']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What protections do civil rights and liberties provide against discrimination and unlawful surveillance in the context of automated systems?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What are the expectations for ensuring that automated systems are safe and effective?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"What do ballot curing laws do to protect voter rights if signature matching fails?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"What criteria for escalating GAI incidents to risk management for safe decommissioning?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the role of tracking the origin and history of AI-generated content in mitigating risks related to authenticity and user trust. It is specific and conveys a clear intent, focusing on the relationship between tracking content and its implications for authenticity and trust. However, the phrasing could be simplified for better clarity. For instance, rephrasing it to 'How does tracking the origin and history of AI-generated content help improve its authenticity and user trust?' would make it more straightforward. Overall, the question is understandable and answerable based on the details provided.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] question compressed: \"What types of resources can help in grasping AI risk management concepts?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What measures are suggested to ensure information integrity in the context of AI systems?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What measures are suggested to manage GAI risks associated with third-party resources?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"How does tracking AI content's origin help with authenticity and trust?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the types of critical resources that should be accessible to individuals and communities as outlined in the Blueprint for an AI Bill of Rights. It is specific in its focus on the Blueprint and the resources it mentions, making the intent clear. However, the question assumes familiarity with the Blueprint for an AI Bill of Rights without providing any context or details about it. To improve clarity and answerability, the question could include a brief description of the Blueprint or specify the types of resources being referred to (e.g., digital literacy, access to technology, data privacy). This would help those unfamiliar with the document to better understand and respond to the question.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question is specific and clear in its intent, asking for factors related to the environmental sustainability and societal implications of GAI systems, with a focus on training data diversity and community feedback mechanisms. It does not rely on external references and can be understood independently. However, it could be improved by specifying what aspects of environmental sustainability and societal implications are of interest (e.g., carbon footprint, social equity) to further guide the response. Overall, the question is well-structured and answerable.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question is specific and clear in its intent, asking for factors related to the environmental sustainability and societal implications of GAI systems, with a focus on training data diversity and community feedback mechanisms. It does not rely on external references and can be understood independently. However, it could be improved by specifying what aspects of environmental sustainability and societal implications are of interest (e.g., carbon footprint, social equity) to further refine the response. Overall, the question is well-structured and answerable.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'Both questions inquire about the role and function of ballot curing laws in the voting process, focusing on their purpose and implications for voter rights. They share the same constraints and depth of inquiry.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the role of the private sector and civil society in the development of the Blueprint for an AI Bill of Rights. It is specific in its focus on the entities involved (private sector and civil society) and the subject matter (AI Bill of Rights). However, the question may require some background knowledge about the Blueprint itself, which is not provided in the question. To improve clarity and answerability, it could be beneficial to include a brief description of what the Blueprint for an AI Bill of Rights entails or the context in which it was developed. This would help ensure that the question is fully self-contained and understandable to those who may not be familiar with the topic.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"What to consider for GAI's sustainability and societal impact, especially on data diversity and community input?\"\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'Both questions inquire about resources related to understanding the AI Risk Management Framework, albeit with slightly different wording. They share the same constraints and requirements, focusing on resources for the same topic.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] evolution_filter failed, retrying with 1\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question focuses on the procedures for escalating incidents, while the second question emphasizes the criteria for escalation. This difference in focus leads to variations in depth and breadth of inquiry, making them not equal.', 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['GAI systems', 'Information integrity', 'Human-AI configuration', 'Digital content transparency', 'Harmful bias and homogenization']\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"What to consider for GAI's enviro sustainability and social impact, especially on data diversity and community input?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the factors that need to be assessed for General Artificial Intelligence (GAI) systems to ensure data privacy and compliance. It is clear in its intent, specifying the focus on data privacy and compliance in the context of GAI systems. However, the term 'factors' is somewhat vague and could benefit from clarification. To improve clarity and answerability, the question could specify whether it is referring to technical factors, regulatory factors, ethical considerations, or a combination of these. Additionally, providing context on the specific compliance standards or frameworks (e.g., GDPR, HIPAA) could enhance the question's clarity.\", 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 1, 'relevance': 3, 'score': 1.75}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Non-consensual dissemination of intimate images', \"Generative AI's value chain\", 'AI privacy risks', 'Data poisoning', 'AI risk management framework']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Biometric Information Privacy Act', 'Transparency for machine learning systems', 'Adverse action notices', 'Explainable AI systems', 'California warehouse employee quotas']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Automated systems', 'Sensitive domains', 'Human oversight', 'Algorithmic discrimination', 'Meaningful access']\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question focuses on the significance of content provenance in risk management, while the second question emphasizes tracking content origin for authenticity and trust. They differ in their specific focus and depth of inquiry regarding AI-generated content.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] question compressed: \"What factors must be assessed for GAI systems to ensure data privacy and compliance?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What measures are suggested for ensuring the accuracy and integrity of information generated by GAI systems?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the protections that civil rights and liberties offer against discrimination and unlawful surveillance specifically in the context of automated systems. It is clear in its intent, specifying the areas of interest (civil rights, liberties, discrimination, unlawful surveillance) and the context (automated systems). However, the question could be improved by clarifying which civil rights and liberties are being referred to, as well as providing a brief context on how automated systems relate to these issues. This would enhance understanding and answerability for those who may not be familiar with the specific legal frameworks or recent developments in this area.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"What protections do civil rights and liberties provide against discrimination and unlawful surveillance in the context of automated systems?\"\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question focuses on assessing the environmental impact of GAI systems, while the second question emphasizes sustainability and societal impact, including data diversity and community input. This leads to different constraints and requirements, as well as varying depths and breadths of inquiry.', 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the expectations for ensuring the safety and effectiveness of automated systems. It is relatively clear in its intent, seeking information on standards or criteria related to the safety and effectiveness of these systems. However, the question is somewhat broad and could benefit from more specificity. For instance, it could clarify whether it is referring to specific types of automated systems (e.g., autonomous vehicles, industrial robots, software systems) or particular contexts (e.g., regulatory frameworks, industry standards). Adding such details would enhance clarity and make the question more focused and answerable.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What are the expectations for ensuring that automated systems are safe and effective?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What research is being conducted to support the implementation of explainable AI systems?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about measures to ensure information integrity specifically in the context of AI systems. It is clear in its intent, specifying the focus on 'information integrity' and 'AI systems', which allows for a direct response. The question is independent and does not rely on external references or additional context, making it understandable and answerable based on the details provided. Therefore, it meets the criteria for clarity and answerability.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What expectations should be met by automated systems used in sensitive domains?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What are the key concerns related to AI privacy risks as discussed in recent literature?\"\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'Both questions address the environmental impact of GAI systems, but the second question specifically emphasizes sustainability, social impact, data diversity, and community input, which introduces additional constraints and requirements not present in the first question.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What safeguards do civil rights and liberties offer against discriminatory practices and unauthorized monitoring in the realm of automated systems, as outlined in the AI Bill of Rights framework?\"\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'Both questions address data privacy and compliance in the context of GAI systems, but the first question specifically mentions localization compliance and risks, which adds depth and specificity not present in the second question.', 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about measures suggested to manage risks associated with Generative AI (GAI) when using third-party resources. It is clear in its intent, specifying the focus on GAI risks and the context of third-party resources. However, the question could benefit from being more specific about the type of measures being sought (e.g., regulatory, technical, operational) or the context in which these measures are applied (e.g., specific industries, types of resources). This would enhance clarity and answerability. Overall, the question is understandable and can be answered based on the details provided, but additional specificity would improve it.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The criteria for escalating GAI incidents to the organizational risk management authority include specific criteria for deactivation or disengagement that are met for a particular context of use or for the GAI system as a whole.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about measures to ensure the accuracy and integrity of information generated by GAI systems. It is clear in its intent, specifying the focus on accuracy and integrity, and it does not rely on external references or context. However, it could be improved by specifying what type of measures (e.g., technical, procedural, ethical) are of interest or by providing a context in which these measures are to be applied (e.g., specific industries, applications). This would help narrow down the response and make it more targeted.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': \"For GAI's sustainability and societal impact, it is important to assess the proportion of synthetic to non-synthetic training data to ensure it is not overly homogenous or GAI-produced. Additionally, documenting anticipated environmental impacts of model development, maintenance, and deployment is crucial. Gathering structured feedback about content provenance from operators, users, and impacted communities is also essential to actively seek feedback on generated content quality and potential biases, thereby ensuring diverse and inclusive content generation.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'Tracking the origin and history of AI-generated content through provenance data helps assess its authenticity and integrity, thereby improving trustworthiness in AI systems. It enables users to have better knowledge of the trustworthiness of both authentic and synthetic content, and when combined with organizational accountability mechanisms, it can trace negative outcomes back to their source, enhancing public trust.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the expectations for ensuring the safety and effectiveness of automated systems. It is relatively clear in its intent, seeking information on standards or criteria related to safety and effectiveness. However, the question is somewhat broad and could benefit from more specificity. For instance, it could clarify whether it is referring to specific types of automated systems (e.g., autonomous vehicles, industrial robots, software systems) or particular contexts (e.g., regulatory frameworks, industry standards). Adding such details would enhance clarity and make the question more focused and answerable.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'Suggested measures to ensure information integrity in the context of AI systems include employing methods to trace the origin and modifications of digital content, integrating tools designed to analyze content provenance and detect data anomalies, verifying the authenticity of digital signatures, and identifying patterns associated with misinformation or manipulation. Additionally, it is recommended to disaggregate evaluation metrics by demographic factors to identify discrepancies in how content provenance mechanisms work across diverse populations.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about key concerns related to AI privacy risks as discussed in recent literature. It is clear in its intent, specifying the topic of interest (AI privacy risks) and the context (recent literature). However, the term 'recent literature' is somewhat vague, as it does not specify a time frame or particular studies, which could lead to different interpretations. To improve clarity and answerability, the question could specify a time frame (e.g., 'in the last year') or mention specific studies or reports that are of interest. This would help narrow down the scope and provide a more focused response.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What are the key concerns related to AI privacy risks as discussed in recent literature?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about research related to the implementation of explainable AI systems. It is relatively clear in its intent, seeking information on ongoing research efforts in this area. However, it is somewhat broad and could benefit from more specificity. For instance, it could specify the type of explainable AI systems (e.g., in healthcare, finance, etc.) or the particular aspects of implementation being researched (e.g., methodologies, frameworks, or case studies). Adding such details would enhance clarity and make the question more focused and answerable.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What research is being conducted to support the implementation of explainable AI systems?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the expectations for automated systems in sensitive domains, which is a clear and specific inquiry. It does not rely on external references and can be understood independently. However, it could benefit from further clarification regarding what is meant by 'sensitive domains' (e.g., healthcare, finance, law enforcement) and what types of expectations are being referred to (e.g., ethical standards, performance metrics, user safety). Adding these details would enhance the clarity and specificity of the question, making it easier to provide a focused answer.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] simple question generated: \"What expectations should be met by automated systems used in sensitive domains?\"\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 3, 'depth': 3, 'structure': 3, 'relevance': 3, 'score': 3.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Automated systems', 'Public consultation', 'Testing and deployment', 'Risk identification and mitigation', 'Safety and effectiveness']\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': \"For GAI's environmental sustainability and social impact, it is important to assess the proportion of synthetic to non-synthetic training data to ensure it is not overly homogenous or GAI-produced. Additionally, documenting anticipated environmental impacts of model development, maintenance, and deployment is crucial. Gathering structured feedback about content provenance from operators, users, and impacted communities is also essential to actively seek feedback on generated content quality and potential biases, thereby ensuring diverse and inclusive content generation.\", 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question seeks to understand the safeguards provided by civil rights and liberties against discriminatory practices and unauthorized monitoring in automated systems, specifically referencing the AI Bill of Rights framework. While it is specific in its focus on civil rights, liberties, and the AI Bill of Rights, it assumes familiarity with the framework without providing any context or details about it. This could make it challenging for those who are not well-versed in the AI Bill of Rights to answer effectively. To improve clarity and answerability, the question could briefly define what the AI Bill of Rights entails or specify which aspects of civil rights and liberties are being referred to. This would help ensure that the question is more accessible to a broader audience.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What safeguards do civil rights and liberties offer against discriminatory practices and unauthorized monitoring in the realm of automated systems, as outlined in the AI Bill of Rights framework?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What steps should be taken for risk identification and mitigation before deploying an automated system?\"\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The suggested measures for ensuring the accuracy and integrity of information generated by GAI systems include reviewing and documenting the accuracy, representativeness, relevance, and suitability of data used at different stages of the AI life cycle; deploying fact-checking techniques to verify the accuracy and veracity of information; developing and implementing testing techniques to identify GAI produced content that might be indistinguishable from human-generated content; and implementing plans for regular adversarial testing to identify vulnerabilities and potential manipulation or misuse.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about research related to the implementation of explainable AI systems. It is relatively clear in its intent, seeking information on ongoing research efforts in this area. However, it could be improved by specifying the type of research (e.g., theoretical, applied, case studies) or the specific aspects of explainable AI systems being investigated (e.g., algorithms, user interfaces, regulatory frameworks). This would help narrow down the scope and make the question more focused and answerable.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"What research is being conducted to support the implementation of explainable AI systems?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question seeks to understand the safeguards provided by civil rights and liberties against discriminatory practices and unauthorized monitoring in automated systems, specifically referencing the AI Bill of Rights framework. While it is specific in its focus on civil rights, liberties, and the AI Bill of Rights, it assumes familiarity with the framework without providing any context or details about it. This could make it challenging for those who are not well-versed in the AI Bill of Rights to answer effectively. To improve clarity and answerability, the question could briefly define what the AI Bill of Rights entails or specify which aspects of civil rights and liberties are being referred to, thereby making it more accessible to a broader audience.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about key concerns related to AI privacy risks as discussed in recent literature. It is clear in its intent to gather information on specific concerns regarding AI privacy. However, the phrase 'recent literature' is somewhat vague, as it does not specify a time frame or particular studies, which could lead to different interpretations of what constitutes 'recent'. To improve clarity and answerability, the question could specify a time frame (e.g., 'in the last year') or mention specific studies or types of literature (e.g., 'academic papers, industry reports') to narrow down the scope of the inquiry.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 2 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Data privacy', 'Surveillance and data collection', 'Consumer data protection', 'Automated systems', 'Mental health impacts']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Stakeholder communities', 'Unacceptable use', 'GAI risks', 'Information integrity', 'Governance and oversight']\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the key factors that help ensure automated systems in sensitive areas avoid discrimination and maintain oversight. It is specific in its focus on automated systems and the issues of discrimination and oversight, making the intent clear. However, the term 'sensitive areas' is somewhat vague and could refer to various contexts such as healthcare, law enforcement, or hiring practices. To improve clarity and answerability, the question could specify which sensitive areas are being referred to or provide examples. This would help narrow down the scope and make it easier to provide a relevant and focused response.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What measures are being taken to address consumer data protection in the United States?\"\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] question compressed: \"What key factors ensure automated systems in sensitive areas avoid discrimination and maintain oversight?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What role does governance and oversight play in the risk management process for GAI systems?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks for specific steps related to risk identification and mitigation prior to deploying an automated system. It is clear in its intent, specifying the focus on risk management in the context of automated systems. However, it could be improved by providing more context about the type of automated system in question (e.g., software, manufacturing, AI) or the specific risks being considered (e.g., operational, security, compliance). This additional detail would help tailor the response more effectively. Overall, the question is understandable and answerable based on the details provided, but could benefit from slight refinement for greater specificity.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"What steps should be taken for risk identification and mitigation before deploying an automated system?\"\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question focuses on expectations in sensitive domains, while the second emphasizes fairness and oversight, which are specific aspects of the broader topic. This leads to different depths and breadths of inquiry.', 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the measures being taken to address consumer data protection in the United States. It is clear and specific, focusing on a particular topic (consumer data protection) and a specific geographic context (the United States). The intent is straightforward, seeking information on current measures or regulations. Therefore, it is understandable and answerable based on the details provided.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"What measures are being taken to address consumer data protection in the United States?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What proactive measures should be implemented to identify and mitigate risks associated with automated systems prior to their deployment, ensuring community consultation and adherence to safety standards?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the role of governance and oversight in the risk management process specifically for GAI (General Artificial Intelligence) systems. It is clear in its intent, focusing on the relationship between governance, oversight, and risk management within a specific context (GAI systems). However, the question could be improved by providing a bit more context or specifying what aspects of governance and oversight are of interest (e.g., regulatory frameworks, ethical considerations, organizational policies). This would help in providing a more targeted and comprehensive answer.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"What role does governance and oversight play in the risk management process for GAI systems?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What strategies are being implemented to enhance consumer data privacy amidst the increasing surveillance practices by both corporations and government entities in the U.S.?\"\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'Fairness and oversight in automated systems are ensured through several expectations: implementing additional human oversight and safeguards, narrowly scoping data and inferences, tailoring systems to specific use cases, requiring human consideration before high-risk decisions, and providing meaningful access to examine the system. Additionally, reporting on the accessibility, timeliness, and effectiveness of human consideration and fallback is essential.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What mechanisms ensure that governance and oversight effectively mitigate unacceptable risks associated with GAI systems while maintaining transparency in their operational processes?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question is specific and clear in its intent, asking for proactive measures to identify and mitigate risks related to automated systems before deployment. It emphasizes the importance of community consultation and adherence to safety standards, which adds context to the inquiry. The question is independent and can be understood without needing additional references. However, it could be improved by specifying the type of automated systems in question (e.g., industrial, transportation, healthcare) to further narrow down the focus and enhance answerability. Overall, it meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"What steps can ensure safe deployment of automated systems with community input?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What ongoing studies are being undertaken to enhance the transparency and accountability of automated systems that significantly influence individual rights and opportunities?\"\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question focuses specifically on risk identification and mitigation, while the second question emphasizes safe deployment with community input, indicating different constraints and requirements.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The answer to given question is not present in context', 'verdict': -1}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': \"To ensure safe deployment of automated systems with community input, the following steps can be taken: 1. Consultation with the public during the design, implementation, deployment, acquisition, and maintenance phases, emphasizing early-stage engagement with diverse impacted communities. 2. Extensive testing of systems before deployment, following domain-specific best practices and mirroring real-world conditions. 3. Identification and mitigation of potential risks before and during deployment, focusing on meaningful impacts on people's rights and opportunities. 4. Ongoing monitoring and evaluation to confirm safety and effectiveness, including independent reporting of steps taken to mitigate potential harms.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The suggested measures to manage GAI risks associated with third-party resources include applying organizational risk tolerances and controls to third-party GAI resources, testing GAI system value chain risks, re-assessing model risks after fine-tuning or retrieval-augmented generation implementation, and taking reasonable measures to review training data for sensitive information and intellectual property.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question addresses the mechanisms of governance and oversight in relation to GAI (General Artificial Intelligence) systems, specifically focusing on risk mitigation and transparency. It is clear in its intent to explore how these mechanisms function to balance risk and transparency. However, the question is somewhat broad and may benefit from more specificity regarding what types of mechanisms are being referred to (e.g., regulatory frameworks, ethical guidelines, technical safeguards) or what specific risks and transparency issues are of concern. To improve clarity and answerability, the question could specify the context or examples of GAI systems being considered, or clarify the particular aspects of governance and oversight that are of interest.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"How do we balance risk management and transparency in GAI governance?\"\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question focuses specifically on governance and oversight in risk management for GAI systems, while the second question addresses the balance between risk management and transparency in governance. This indicates different scopes and depths of inquiry.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The answer to given question is not present in context', 'verdict': -1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about ongoing studies aimed at improving the transparency and accountability of automated systems that impact individual rights and opportunities. It is specific in its focus on 'ongoing studies' and the context of 'automated systems'. However, the term 'automated systems' is broad and could encompass various technologies and applications, which may lead to ambiguity in the type of studies being referred to. To enhance clarity and answerability, the question could specify the types of automated systems (e.g., AI algorithms, decision-making systems) or the particular rights and opportunities being considered. This would help narrow down the scope and make it easier to provide a relevant response.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What ongoing studies are being undertaken to enhance the transparency and accountability of automated systems that significantly influence individual rights and opportunities?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question inquires about ongoing studies aimed at improving the transparency and accountability of automated systems that impact individual rights and opportunities. It is specific in its focus on 'ongoing studies' and the context of 'automated systems' affecting 'individual rights and opportunities'. However, the term 'automated systems' is broad and could refer to various technologies, such as AI, algorithms, or decision-making systems. To enhance clarity and answerability, the question could specify the type of automated systems being referred to (e.g., AI in hiring, algorithmic decision-making in finance) or provide examples of the studies or areas of research being considered. This would help narrow down the scope and make it easier to provide a relevant response.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"What studies aim to improve transparency in automated systems affecting rights?\"\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question focuses specifically on research related to explainable AI systems, while the second question addresses studies aimed at improving transparency in automated systems, which may not necessarily be limited to AI. This difference in focus leads to a variation in depth and breadth of inquiry.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': \"The National Institute of Standards and Technology (NIST) is conducting fundamental research on the explainability of AI systems, while the Defense Advanced Research Projects Agency (DARPA) has a program on Explainable Artificial Intelligence aimed at creating machine learning techniques that produce more explainable models. Additionally, the National Science Foundation's program on Fairness in Artificial Intelligence includes research foundations for explainable AI.\", 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question is specific and clear, asking about strategies to enhance consumer data privacy in the context of increasing surveillance by corporations and government entities in the U.S. It does not rely on external references and can be understood independently. The intent is clear, seeking information on specific strategies related to consumer data privacy. Therefore, it meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"What strategies are in place to boost consumer data privacy amid rising surveillance in the U.S.?\"\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': \"Both questions focus on consumer data protection and privacy in the United States, but they differ in their emphasis on 'measures' versus 'strategies' and the context of 'rising surveillance', which affects the depth and breadth of inquiry.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'Some companies are taking concerns about consumer data privacy seriously by integrating mechanisms to protect privacy into their products by design and by default. This includes minimizing the data they collect, clearly communicating data collection and use, and improving security practices. Additionally, federal government surveillance and data collection is governed by legal protections that help protect civil liberties and provide limits on data retention in some cases. Many states have also enacted consumer data privacy protection regimes to address some of these harms.', 'verdict': 1}\n"
     ]
    }
   ],
   "source": [
    "testset = generator.generate_with_langchain_docs(documents, 20, distributions, with_debugging_logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What criteria are used to measure AI system pe...</td>\n",
       "      <td>[ \\n30 \\nMEASURE 2.2: Evaluations involving hu...</td>\n",
       "      <td>AI system performance or assurance criteria ar...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'NIST_report.pdf', 'file_path': 'N...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What applications can GAI technologies be leve...</td>\n",
       "      <td>[ \\n51 \\ngeneral public participants. For exam...</td>\n",
       "      <td>GAI technologies can be leveraged for many app...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'NIST_report.pdf', 'file_path': 'N...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What was the purpose of the meetings conducted...</td>\n",
       "      <td>[APPENDIX\\n• OSTP conducted meetings with a va...</td>\n",
       "      <td>The purpose of the meetings conducted by OSTP ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'Blueprint-for-an-AI-Bill-of-Right...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the intellectual property risks assoc...</td>\n",
       "      <td>[ \\n11 \\nvalue chain (e.g., data inputs, proce...</td>\n",
       "      <td>Intellectual property risks from GAI systems m...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'NIST_report.pdf', 'file_path': 'N...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What measures are suggested for ensuring the a...</td>\n",
       "      <td>[ \\n25 \\nMP-2.3-002 Review and document accura...</td>\n",
       "      <td>The suggested measures for ensuring the accura...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'NIST_report.pdf', 'file_path': 'N...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What measures are suggested to manage GAI risk...</td>\n",
       "      <td>[ \\n42 \\nMG-2.4-002 \\nEstablish and maintain p...</td>\n",
       "      <td>The suggested measures to manage GAI risks ass...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'NIST_report.pdf', 'file_path': 'N...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What measures are suggested to ensure informat...</td>\n",
       "      <td>[ \\n28 \\nMAP 5.2: Practices and personnel for ...</td>\n",
       "      <td>Suggested measures to ensure information integ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'NIST_report.pdf', 'file_path': 'N...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What are the key considerations regarding data...</td>\n",
       "      <td>[TABLE OF CONTENTS\\nFROM PRINCIPLES TO PRACTIC...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'Blueprint-for-an-AI-Bill-of-Right...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What are some examples of how data privacy pri...</td>\n",
       "      <td>[ \\n \\n  \\n \\nDATA PRIVACY \\nWHY THIS PRINCIPL...</td>\n",
       "      <td>Some examples of how data privacy principles a...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'Blueprint-for-an-AI-Bill-of-Right...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What organizational practices are necessary fo...</td>\n",
       "      <td>[ \\n19 \\nGV-4.1-003 \\nEstablish policies, proc...</td>\n",
       "      <td>Organizational practices necessary for enablin...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'NIST_report.pdf', 'file_path': 'N...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What to consider for GAI's enviro sustainabili...</td>\n",
       "      <td>[ \\n37 \\nMS-2.11-005 \\nAssess the proportion o...</td>\n",
       "      <td>For GAI's environmental sustainability and soc...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'NIST_report.pdf', 'file_path': 'N...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What criteria for escalating GAI incidents to ...</td>\n",
       "      <td>[ \\n42 \\nMG-2.4-002 \\nEstablish and maintain p...</td>\n",
       "      <td>The criteria for escalating GAI incidents to t...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'NIST_report.pdf', 'file_path': 'N...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What studies aim to improve transparency in au...</td>\n",
       "      <td>[ \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n...</td>\n",
       "      <td>The National Institute of Standards and Techno...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'Blueprint-for-an-AI-Bill-of-Right...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What strategies are in place to boost consumer...</td>\n",
       "      <td>[ \\n \\n  \\n \\n \\n \\nDATA PRIVACY \\nWHY THIS PR...</td>\n",
       "      <td>Some companies are taking concerns about consu...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'Blueprint-for-an-AI-Bill-of-Right...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What steps can ensure safe deployment of autom...</td>\n",
       "      <td>[ \\n \\n \\n \\n \\n \\n \\nSAFE AND EFFECTIVE \\nSYS...</td>\n",
       "      <td>To ensure safe deployment of automated systems...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'Blueprint-for-an-AI-Bill-of-Right...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>How does tracking AI content's origin help wit...</td>\n",
       "      <td>[ \\n51 \\ngeneral public participants. For exam...</td>\n",
       "      <td>Tracking the origin and history of AI-generate...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'NIST_report.pdf', 'file_path': 'N...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>How do we balance risk management and transpar...</td>\n",
       "      <td>[ \\n15 \\nGV-1.3-004 Obtain input from stakehol...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'NIST_report.pdf', 'file_path': 'N...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>What to consider for GAI's sustainability and ...</td>\n",
       "      <td>[ \\n37 \\nMS-2.11-005 \\nAssess the proportion o...</td>\n",
       "      <td>For GAI's sustainability and societal impact, ...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'NIST_report.pdf', 'file_path': 'N...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What ensures fairness and oversight in automat...</td>\n",
       "      <td>[ \\n \\n \\n \\n \\n \\n \\nHUMAN ALTERNATIVES, \\nCO...</td>\n",
       "      <td>Fairness and oversight in automated systems ar...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'Blueprint-for-an-AI-Bill-of-Right...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>What factors to consider for GAI data privacy ...</td>\n",
       "      <td>[ \\n42 \\nMG-2.4-002 \\nEstablish and maintain p...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'NIST_report.pdf', 'file_path': 'N...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0   What criteria are used to measure AI system pe...   \n",
       "1   What applications can GAI technologies be leve...   \n",
       "2   What was the purpose of the meetings conducted...   \n",
       "3   What are the intellectual property risks assoc...   \n",
       "4   What measures are suggested for ensuring the a...   \n",
       "5   What measures are suggested to manage GAI risk...   \n",
       "6   What measures are suggested to ensure informat...   \n",
       "7   What are the key considerations regarding data...   \n",
       "8   What are some examples of how data privacy pri...   \n",
       "9   What organizational practices are necessary fo...   \n",
       "10  What to consider for GAI's enviro sustainabili...   \n",
       "11  What criteria for escalating GAI incidents to ...   \n",
       "12  What studies aim to improve transparency in au...   \n",
       "13  What strategies are in place to boost consumer...   \n",
       "14  What steps can ensure safe deployment of autom...   \n",
       "15  How does tracking AI content's origin help wit...   \n",
       "16  How do we balance risk management and transpar...   \n",
       "17  What to consider for GAI's sustainability and ...   \n",
       "18  What ensures fairness and oversight in automat...   \n",
       "19  What factors to consider for GAI data privacy ...   \n",
       "\n",
       "                                             contexts  \\\n",
       "0   [ \\n30 \\nMEASURE 2.2: Evaluations involving hu...   \n",
       "1   [ \\n51 \\ngeneral public participants. For exam...   \n",
       "2   [APPENDIX\\n• OSTP conducted meetings with a va...   \n",
       "3   [ \\n11 \\nvalue chain (e.g., data inputs, proce...   \n",
       "4   [ \\n25 \\nMP-2.3-002 Review and document accura...   \n",
       "5   [ \\n42 \\nMG-2.4-002 \\nEstablish and maintain p...   \n",
       "6   [ \\n28 \\nMAP 5.2: Practices and personnel for ...   \n",
       "7   [TABLE OF CONTENTS\\nFROM PRINCIPLES TO PRACTIC...   \n",
       "8   [ \\n \\n  \\n \\nDATA PRIVACY \\nWHY THIS PRINCIPL...   \n",
       "9   [ \\n19 \\nGV-4.1-003 \\nEstablish policies, proc...   \n",
       "10  [ \\n37 \\nMS-2.11-005 \\nAssess the proportion o...   \n",
       "11  [ \\n42 \\nMG-2.4-002 \\nEstablish and maintain p...   \n",
       "12  [ \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n...   \n",
       "13  [ \\n \\n  \\n \\n \\n \\nDATA PRIVACY \\nWHY THIS PR...   \n",
       "14  [ \\n \\n \\n \\n \\n \\n \\nSAFE AND EFFECTIVE \\nSYS...   \n",
       "15  [ \\n51 \\ngeneral public participants. For exam...   \n",
       "16  [ \\n15 \\nGV-1.3-004 Obtain input from stakehol...   \n",
       "17  [ \\n37 \\nMS-2.11-005 \\nAssess the proportion o...   \n",
       "18  [ \\n \\n \\n \\n \\n \\n \\nHUMAN ALTERNATIVES, \\nCO...   \n",
       "19  [ \\n42 \\nMG-2.4-002 \\nEstablish and maintain p...   \n",
       "\n",
       "                                         ground_truth evolution_type  \\\n",
       "0   AI system performance or assurance criteria ar...         simple   \n",
       "1   GAI technologies can be leveraged for many app...         simple   \n",
       "2   The purpose of the meetings conducted by OSTP ...         simple   \n",
       "3   Intellectual property risks from GAI systems m...         simple   \n",
       "4   The suggested measures for ensuring the accura...         simple   \n",
       "5   The suggested measures to manage GAI risks ass...         simple   \n",
       "6   Suggested measures to ensure information integ...         simple   \n",
       "7   The answer to given question is not present in...         simple   \n",
       "8   Some examples of how data privacy principles a...         simple   \n",
       "9   Organizational practices necessary for enablin...         simple   \n",
       "10  For GAI's environmental sustainability and soc...  multi_context   \n",
       "11  The criteria for escalating GAI incidents to t...  multi_context   \n",
       "12  The National Institute of Standards and Techno...  multi_context   \n",
       "13  Some companies are taking concerns about consu...  multi_context   \n",
       "14  To ensure safe deployment of automated systems...  multi_context   \n",
       "15  Tracking the origin and history of AI-generate...  multi_context   \n",
       "16  The answer to given question is not present in...  multi_context   \n",
       "17  For GAI's sustainability and societal impact, ...  multi_context   \n",
       "18  Fairness and oversight in automated systems ar...      reasoning   \n",
       "19  The answer to given question is not present in...      reasoning   \n",
       "\n",
       "                                             metadata  episode_done  \n",
       "0   [{'source': 'NIST_report.pdf', 'file_path': 'N...          True  \n",
       "1   [{'source': 'NIST_report.pdf', 'file_path': 'N...          True  \n",
       "2   [{'source': 'Blueprint-for-an-AI-Bill-of-Right...          True  \n",
       "3   [{'source': 'NIST_report.pdf', 'file_path': 'N...          True  \n",
       "4   [{'source': 'NIST_report.pdf', 'file_path': 'N...          True  \n",
       "5   [{'source': 'NIST_report.pdf', 'file_path': 'N...          True  \n",
       "6   [{'source': 'NIST_report.pdf', 'file_path': 'N...          True  \n",
       "7   [{'source': 'Blueprint-for-an-AI-Bill-of-Right...          True  \n",
       "8   [{'source': 'Blueprint-for-an-AI-Bill-of-Right...          True  \n",
       "9   [{'source': 'NIST_report.pdf', 'file_path': 'N...          True  \n",
       "10  [{'source': 'NIST_report.pdf', 'file_path': 'N...          True  \n",
       "11  [{'source': 'NIST_report.pdf', 'file_path': 'N...          True  \n",
       "12  [{'source': 'Blueprint-for-an-AI-Bill-of-Right...          True  \n",
       "13  [{'source': 'Blueprint-for-an-AI-Bill-of-Right...          True  \n",
       "14  [{'source': 'Blueprint-for-an-AI-Bill-of-Right...          True  \n",
       "15  [{'source': 'NIST_report.pdf', 'file_path': 'N...          True  \n",
       "16  [{'source': 'NIST_report.pdf', 'file_path': 'N...          True  \n",
       "17  [{'source': 'NIST_report.pdf', 'file_path': 'N...          True  \n",
       "18  [{'source': 'Blueprint-for-an-AI-Bill-of-Right...          True  \n",
       "19  [{'source': 'NIST_report.pdf', 'file_path': 'N...          True  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangSmith Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "dataset_name = \"AI Questions\"\n",
    "\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"Questions about responsibly managing AI\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in testset.to_pandas().iterrows():\n",
    "  client.create_example(\n",
    "      inputs={\n",
    "          \"question\": test[1][\"question\"]\n",
    "      },\n",
    "      outputs={\n",
    "          \"answer\": test[1][\"ground_truth\"]\n",
    "      },\n",
    "      metadata={\n",
    "          \"context\": test[0]\n",
    "      },\n",
    "      dataset_id=dataset.id\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_documents = documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 50\n",
    ")\n",
    "\n",
    "rag_documents = text_splitter.split_documents(rag_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Qdrant\n",
    "\n",
    "vectorstore = Qdrant.from_documents(\n",
    "    documents=rag_documents,\n",
    "    embedding=embeddings,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"Responsible AI\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "RAG_PROMPT = \"\"\"\\\n",
    "Given a provided context and question, you must answer the question based only on context.\n",
    "\n",
    "If you cannot answer the question based on the context - you must say \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "primary_qa_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "retrieval_augmented_qa_chain = (\n",
    "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
    "    # \"question\" : populated by getting the value of the \"question\" key\n",
    "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
    "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
    "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
    "    #              by getting the value of the \"context\" key from the previous step\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
    "    #              into the LLM and stored in a key called \"response\"\n",
    "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
    "    | {\"response\": rag_prompt | primary_qa_llm, \"context\": itemgetter(\"context\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': AIMessage(content='Some responsible ways to use AI include ensuring that AI is lawful and respectful of national values, purposeful and performance-driven, accurate, reliable, and effective, safe, secure, and resilient, understandable, responsible and traceable, regularly monitored, transparent, and accountable.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 1169, 'total_tokens': 1221, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_1bb46167f9', 'finish_reason': 'stop', 'logprobs': None}, id='run-f19b79a0-d837-4c8f-b8b9-4da21f440dce-0', usage_metadata={'input_tokens': 1169, 'output_tokens': 52, 'total_tokens': 1221}),\n",
       " 'context': [Document(metadata={'source': 'Blueprint-for-an-AI-Bill-of-Rights.pdf', 'file_path': 'Blueprint-for-an-AI-Bill-of-Rights.pdf', 'page': 20, 'total_pages': 73, 'format': 'PDF 1.6', 'title': 'Blueprint for an AI Bill of Rights', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe Illustrator 26.3 (Macintosh)', 'producer': 'iLovePDF', 'creationDate': \"D:20220920133035-04'00'\", 'modDate': \"D:20221003104118-04'00'\", 'trapped': '', '_id': '208c8aac5cbd40219e4c02d08df989fd', '_collection_name': 'Responsible AI'}, page_content='safe, secure, and resilient; (e) understandable; (f ) responsible and traceable; (g) regularly monitored; (h) transpar-\\nent; and, (i) accountable. The Blueprint for an AI Bill of Rights is consistent with the Executive Order. \\nAffected agencies across the federal government have released AI use case inventories13 and are implementing \\nplans to bring those AI systems into compliance with the Executive Order or retire them.'),\n",
       "  Document(metadata={'source': 'NIST_report.pdf', 'file_path': 'NIST_report.pdf', 'page': 44, 'total_pages': 64, 'format': 'PDF 1.6', 'title': 'Artificial Intelligence Risk Management Framework: Generative Artificial Intelligence Profile', 'author': 'National Institute of Standards and Technology', 'subject': '', 'keywords': '', 'creator': 'Acrobat PDFMaker 24 for Word', 'producer': 'Adobe PDF Library 24.2.159', 'creationDate': \"D:20240805141702-04'00'\", 'modDate': \"D:20240805143048-04'00'\", 'trapped': '', '_id': 'a9beca7cb8074f4988f8aa16c5bd0094', '_collection_name': 'Responsible AI'}, page_content='41 \\nMG-2.2-006 \\nUse feedback from internal and external AI Actors, users, individuals, and \\ncommunities, to assess impact of AI-generated content. \\nHuman-AI Conﬁguration \\nMG-2.2-007 \\nUse real-time auditing tools where they can be demonstrated to aid in the \\ntracking and validation of the lineage and authenticity of AI-generated data. \\nInformation Integrity \\nMG-2.2-008 \\nUse structured feedback mechanisms to solicit and capture user input about AI-'),\n",
       "  Document(metadata={'source': 'Blueprint-for-an-AI-Bill-of-Rights.pdf', 'file_path': 'Blueprint-for-an-AI-Bill-of-Rights.pdf', 'page': 20, 'total_pages': 73, 'format': 'PDF 1.6', 'title': 'Blueprint for an AI Bill of Rights', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe Illustrator 26.3 (Macintosh)', 'producer': 'iLovePDF', 'creationDate': \"D:20220920133035-04'00'\", 'modDate': \"D:20221003104118-04'00'\", 'trapped': '', '_id': '4325da2f40f04431b01e510884e73bd0', '_collection_name': 'Responsible AI'}, page_content='designing, developing, acquiring, or using AI for purposes other than national security or \\ndefense. These principles—while taking into account the sensitive law enforcement and other contexts in which \\nthe federal government may use AI, as opposed to private sector use of AI—require that AI is: (a) lawful and \\nrespectful of our Nation’s values; (b) purposeful and performance-driven; (c) accurate, reliable, and effective; (d)'),\n",
       "  Document(metadata={'source': 'NIST_report.pdf', 'file_path': 'NIST_report.pdf', 'page': 50, 'total_pages': 64, 'format': 'PDF 1.6', 'title': 'Artificial Intelligence Risk Management Framework: Generative Artificial Intelligence Profile', 'author': 'National Institute of Standards and Technology', 'subject': '', 'keywords': '', 'creator': 'Acrobat PDFMaker 24 for Word', 'producer': 'Adobe PDF Library 24.2.159', 'creationDate': \"D:20240805141702-04'00'\", 'modDate': \"D:20240805143048-04'00'\", 'trapped': '', '_id': '0e9bb9efd1da410f89817f8e3824b6c5', '_collection_name': 'Responsible AI'}, page_content='applications and contexts of use. These can include data labeling and preparation, development of GAI \\nmodels, content moderation, code generation and review, text generation and editing, image and video \\ngeneration, summarization, search, and chat. These activities can take place within organizational \\nsettings or in the public domain. \\nOrganizations can restrict AI applications that cause harm, exceed stated risk tolerances, or that conﬂict')]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_augmented_qa_chain.invoke({\"question\" : \"What are some responsible ways to use AI?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangSmith Evaluation Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_df = testset.to_pandas()\n",
    "test_questions = testset_df['question'].values.tolist()\n",
    "test_groundtruths = testset_df['ground_truth'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for question in test_questions:\n",
    "  response = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
    "  answers.append(response[\"response\"].content)\n",
    "  contexts.append([context.page_content for context in response[\"context\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "response_dataset = Dataset.from_dict({\n",
    "    \"question\" : test_questions,\n",
    "    \"answer\" : answers,\n",
    "    \"contexts\" : contexts,\n",
    "    \"ground_truth\" : test_groundtruths\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    answer_correctness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "metrics = [\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    answer_correctness,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec0577f7b254e34a01f1db06a542259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = evaluate(response_dataset, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 0.7963, 'answer_relevancy': 0.8297, 'context_recall': 0.7458, 'context_precision': 0.7903, 'answer_correctness': 0.5693}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>answer_correctness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What criteria are used to measure AI system pe...</td>\n",
       "      <td>[and Homogenization \\nAI Actor Tasks: AI Deplo...</td>\n",
       "      <td>AI system performance or assurance criteria ar...</td>\n",
       "      <td>AI system performance or assurance criteria ar...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958068</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What applications can GAI technologies be leve...</td>\n",
       "      <td>[assessments, and alerting, dynamic risk asses...</td>\n",
       "      <td>GAI technologies can be leveraged for applicat...</td>\n",
       "      <td>GAI technologies can be leveraged for many app...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968036</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.362548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What was the purpose of the meetings conducted...</td>\n",
       "      <td>[APPENDIX\\n• OSTP conducted meetings with a va...</td>\n",
       "      <td>The purpose of the meetings conducted by OSTP ...</td>\n",
       "      <td>The purpose of the meetings conducted by OSTP ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.999684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the intellectual property risks assoc...</td>\n",
       "      <td>[2.10. \\nIntellectual Property \\nIntellectual ...</td>\n",
       "      <td>Intellectual property risks from GAI systems m...</td>\n",
       "      <td>Intellectual property risks from GAI systems m...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991580</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.747246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What measures are suggested for ensuring the a...</td>\n",
       "      <td>[Suggested Action \\nGAI Risks \\nMP-2.2-001 \\nI...</td>\n",
       "      <td>The suggested measures for ensuring the accura...</td>\n",
       "      <td>The suggested measures for ensuring the accura...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.362176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What measures are suggested to manage GAI risk...</td>\n",
       "      <td>[GAI resources; Apply organizational risk tole...</td>\n",
       "      <td>The suggested measures to manage GAI risks ass...</td>\n",
       "      <td>The suggested measures to manage GAI risks ass...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.577877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What measures are suggested to ensure informat...</td>\n",
       "      <td>[or risks of bias or homogenization. \\nThere m...</td>\n",
       "      <td>The suggested measures to ensure information i...</td>\n",
       "      <td>Suggested measures to ensure information integ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.697974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What are the key considerations regarding data...</td>\n",
       "      <td>[Applying The Blueprint for an AI Bill of Righ...</td>\n",
       "      <td>The key considerations regarding data privacy ...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.179462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What are some examples of how data privacy pri...</td>\n",
       "      <td>[DATA PRIVACY \\nWHY THIS PRINCIPLE IS IMPORTAN...</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>Some examples of how data privacy principles a...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.177616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What organizational practices are necessary fo...</td>\n",
       "      <td>[GOVERN 4.3: Organizational practices are in p...</td>\n",
       "      <td>Organizational practices necessary for enablin...</td>\n",
       "      <td>Organizational practices necessary for enablin...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.843065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What to consider for GAI's enviro sustainabili...</td>\n",
       "      <td>[impacted communities. \\nEnvironmental; Harmfu...</td>\n",
       "      <td>To consider GAI's environmental sustainability...</td>\n",
       "      <td>For GAI's environmental sustainability and soc...</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.932567</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.787227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What criteria for escalating GAI incidents to ...</td>\n",
       "      <td>[42 \\nMG-2.4-002 \\nEstablish and maintain proc...</td>\n",
       "      <td>The criteria for escalating GAI incidents to t...</td>\n",
       "      <td>The criteria for escalating GAI incidents to t...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.935536</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What studies aim to improve transparency in au...</td>\n",
       "      <td>[transparency to the public in the mitigation ...</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>The National Institute of Standards and Techno...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.180680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What strategies are in place to boost consumer...</td>\n",
       "      <td>[Increasingly, some companies are taking these...</td>\n",
       "      <td>Some companies are integrating mechanisms to p...</td>\n",
       "      <td>Some companies are taking concerns about consu...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905055</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.804929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What steps can ensure safe deployment of autom...</td>\n",
       "      <td>[maintenance phases of automated system develo...</td>\n",
       "      <td>To ensure safe deployment of automated systems...</td>\n",
       "      <td>To ensure safe deployment of automated systems...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994102</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.521668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>How does tracking AI content's origin help wit...</td>\n",
       "      <td>[history of content. Provenance data tracking ...</td>\n",
       "      <td>Tracking AI content's origin helps with authen...</td>\n",
       "      <td>Tracking the origin and history of AI-generate...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>How do we balance risk management and transpar...</td>\n",
       "      <td>[Suggested Action \\nGAI Risks \\nGV-4.1-001 \\nE...</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.195204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>What to consider for GAI's sustainability and ...</td>\n",
       "      <td>[29 \\nMS-1.1-006 \\nImplement continuous monito...</td>\n",
       "      <td>For GAI's sustainability and societal impact, ...</td>\n",
       "      <td>For GAI's sustainability and societal impact, ...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.937307</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.589181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What ensures fairness and oversight in automat...</td>\n",
       "      <td>[safeguards against human bias, should be prop...</td>\n",
       "      <td>Fairness and oversight in automated systems ar...</td>\n",
       "      <td>Fairness and oversight in automated systems ar...</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.984007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.416015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>What factors to consider for GAI data privacy ...</td>\n",
       "      <td>[reporting, data protection, data privacy, or ...</td>\n",
       "      <td>The factors to consider for GAI data privacy a...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995937</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.176277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0   What criteria are used to measure AI system pe...   \n",
       "1   What applications can GAI technologies be leve...   \n",
       "2   What was the purpose of the meetings conducted...   \n",
       "3   What are the intellectual property risks assoc...   \n",
       "4   What measures are suggested for ensuring the a...   \n",
       "5   What measures are suggested to manage GAI risk...   \n",
       "6   What measures are suggested to ensure informat...   \n",
       "7   What are the key considerations regarding data...   \n",
       "8   What are some examples of how data privacy pri...   \n",
       "9   What organizational practices are necessary fo...   \n",
       "10  What to consider for GAI's enviro sustainabili...   \n",
       "11  What criteria for escalating GAI incidents to ...   \n",
       "12  What studies aim to improve transparency in au...   \n",
       "13  What strategies are in place to boost consumer...   \n",
       "14  What steps can ensure safe deployment of autom...   \n",
       "15  How does tracking AI content's origin help wit...   \n",
       "16  How do we balance risk management and transpar...   \n",
       "17  What to consider for GAI's sustainability and ...   \n",
       "18  What ensures fairness and oversight in automat...   \n",
       "19  What factors to consider for GAI data privacy ...   \n",
       "\n",
       "                                             contexts  \\\n",
       "0   [and Homogenization \\nAI Actor Tasks: AI Deplo...   \n",
       "1   [assessments, and alerting, dynamic risk asses...   \n",
       "2   [APPENDIX\\n• OSTP conducted meetings with a va...   \n",
       "3   [2.10. \\nIntellectual Property \\nIntellectual ...   \n",
       "4   [Suggested Action \\nGAI Risks \\nMP-2.2-001 \\nI...   \n",
       "5   [GAI resources; Apply organizational risk tole...   \n",
       "6   [or risks of bias or homogenization. \\nThere m...   \n",
       "7   [Applying The Blueprint for an AI Bill of Righ...   \n",
       "8   [DATA PRIVACY \\nWHY THIS PRINCIPLE IS IMPORTAN...   \n",
       "9   [GOVERN 4.3: Organizational practices are in p...   \n",
       "10  [impacted communities. \\nEnvironmental; Harmfu...   \n",
       "11  [42 \\nMG-2.4-002 \\nEstablish and maintain proc...   \n",
       "12  [transparency to the public in the mitigation ...   \n",
       "13  [Increasingly, some companies are taking these...   \n",
       "14  [maintenance phases of automated system develo...   \n",
       "15  [history of content. Provenance data tracking ...   \n",
       "16  [Suggested Action \\nGAI Risks \\nGV-4.1-001 \\nE...   \n",
       "17  [29 \\nMS-1.1-006 \\nImplement continuous monito...   \n",
       "18  [safeguards against human bias, should be prop...   \n",
       "19  [reporting, data protection, data privacy, or ...   \n",
       "\n",
       "                                               answer  \\\n",
       "0   AI system performance or assurance criteria ar...   \n",
       "1   GAI technologies can be leveraged for applicat...   \n",
       "2   The purpose of the meetings conducted by OSTP ...   \n",
       "3   Intellectual property risks from GAI systems m...   \n",
       "4   The suggested measures for ensuring the accura...   \n",
       "5   The suggested measures to manage GAI risks ass...   \n",
       "6   The suggested measures to ensure information i...   \n",
       "7   The key considerations regarding data privacy ...   \n",
       "8                                       I don't know.   \n",
       "9   Organizational practices necessary for enablin...   \n",
       "10  To consider GAI's environmental sustainability...   \n",
       "11  The criteria for escalating GAI incidents to t...   \n",
       "12                                      I don't know.   \n",
       "13  Some companies are integrating mechanisms to p...   \n",
       "14  To ensure safe deployment of automated systems...   \n",
       "15  Tracking AI content's origin helps with authen...   \n",
       "16                                      I don't know.   \n",
       "17  For GAI's sustainability and societal impact, ...   \n",
       "18  Fairness and oversight in automated systems ar...   \n",
       "19  The factors to consider for GAI data privacy a...   \n",
       "\n",
       "                                         ground_truth  faithfulness  \\\n",
       "0   AI system performance or assurance criteria ar...      1.000000   \n",
       "1   GAI technologies can be leveraged for many app...      1.000000   \n",
       "2   The purpose of the meetings conducted by OSTP ...      1.000000   \n",
       "3   Intellectual property risks from GAI systems m...      1.000000   \n",
       "4   The suggested measures for ensuring the accura...      1.000000   \n",
       "5   The suggested measures to manage GAI risks ass...      1.000000   \n",
       "6   Suggested measures to ensure information integ...      1.000000   \n",
       "7   The answer to given question is not present in...      1.000000   \n",
       "8   Some examples of how data privacy principles a...      0.000000   \n",
       "9   Organizational practices necessary for enablin...      1.000000   \n",
       "10  For GAI's environmental sustainability and soc...      0.823529   \n",
       "11  The criteria for escalating GAI incidents to t...      0.500000   \n",
       "12  The National Institute of Standards and Techno...      0.000000   \n",
       "13  Some companies are taking concerns about consu...      1.000000   \n",
       "14  To ensure safe deployment of automated systems...      1.000000   \n",
       "15  Tracking the origin and history of AI-generate...      1.000000   \n",
       "16  The answer to given question is not present in...      0.000000   \n",
       "17  For GAI's sustainability and societal impact, ...      0.888889   \n",
       "18  Fairness and oversight in automated systems ar...      0.714286   \n",
       "19  The answer to given question is not present in...      1.000000   \n",
       "\n",
       "    answer_relevancy  context_recall  context_precision  answer_correctness  \n",
       "0           0.958068        1.000000           1.000000            1.000000  \n",
       "1           0.968036        1.000000           0.500000            0.362548  \n",
       "2           1.000000        1.000000           0.805556            0.999684  \n",
       "3           0.991580        0.500000           1.000000            0.747246  \n",
       "4           1.000000        0.500000           1.000000            0.362176  \n",
       "5           0.999999        0.750000           1.000000            0.577877  \n",
       "6           0.991402        0.000000           0.416667            0.697974  \n",
       "7           1.000000        1.000000           0.000000            0.179462  \n",
       "8           0.000000        1.000000           1.000000            0.177616  \n",
       "9           1.000000        0.666667           1.000000            0.843065  \n",
       "10          0.932567        0.250000           0.916667            0.787227  \n",
       "11          0.935536        1.000000           1.000000            0.994350  \n",
       "12          0.000000        0.000000           1.000000            0.180680  \n",
       "13          0.905055        1.000000           0.916667            0.804929  \n",
       "14          0.994102        1.000000           1.000000            0.521668  \n",
       "15          1.000000        1.000000           1.000000            0.773651  \n",
       "16          0.000000        1.000000           0.000000            0.195204  \n",
       "17          0.937307        0.250000           1.000000            0.589181  \n",
       "18          0.984007        1.000000           1.000000            0.416015  \n",
       "19          0.995937        1.000000           0.250000            0.176277  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = results.to_pandas()\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-ops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
